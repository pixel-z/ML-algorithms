{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y45yhDufI5Uo"
      },
      "source": [
        "# **RNN**\n",
        "A recurrent neural network (RNN) is a class of artificial neural network where connections between units form a directed cycle. This creates an internal state of the network which allows it to exhibit dynamic temporal behavior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55i8db8uI5U3"
      },
      "source": [
        "IMDB sentiment classification task\n",
        "\n",
        "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. IMDB provided a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well. Raw text and already processed bag of words formats are provided.\n",
        "\n",
        "You can download the dataset from http://ai.stanford.edu/~amaas/data/sentiment/  or you can directly use \n",
        "\" from keras.datasets import imdb \" to import the dataset.\n",
        "\n",
        "Few points to be noted:\n",
        "Modules like SimpleRNN, LSTM, Activation layers, Dense layers, Dropout can be directly used from keras\n",
        "For preprocessing, you can use required "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SozhvLNkI5U6",
        "outputId": "fc20ba1d-db18-41ba-ebf4-cbe214da3572"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n",
            "17473536/17464789 [==============================] - 1s 0us/step\n",
            "Loaded dataset with 25000 training samples, 25000 test samples\n"
          ]
        }
      ],
      "source": [
        "#load the imdb dataset \n",
        "from keras.datasets import imdb\n",
        "\n",
        "vocabulary_size = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)\n",
        "print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrilwfurI5VA",
        "outputId": "2335cfeb-1803-475e-afa3-cf84fa233ad2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---review---\n",
            "[1, 249, 1323, 7, 61, 113, 10, 10, 13, 1637, 14, 20, 56, 33, 2401, 18, 457, 88, 13, 2626, 1400, 45, 3171, 13, 70, 79, 49, 706, 919, 13, 16, 355, 340, 355, 1696, 96, 143, 4, 22, 32, 289, 7, 61, 369, 71, 2359, 5, 13, 16, 131, 2073, 249, 114, 249, 229, 249, 20, 13, 28, 126, 110, 13, 473, 8, 569, 61, 419, 56, 429, 6, 1513, 18, 35, 534, 95, 474, 570, 5, 25, 124, 138, 88, 12, 421, 1543, 52, 725, 2, 61, 419, 11, 13, 1571, 15, 1543, 20, 11, 4, 2, 5, 296, 12, 3524, 5, 15, 421, 128, 74, 233, 334, 207, 126, 224, 12, 562, 298, 2167, 1272, 7, 2601, 5, 516, 988, 43, 8, 79, 120, 15, 595, 13, 784, 25, 3171, 18, 165, 170, 143, 19, 14, 5, 2, 6, 226, 251, 7, 61, 113]\n",
            "---label---\n",
            "0\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n",
            "---review with words---\n",
            "['the', 'sure', 'themes', 'br', 'only', 'acting', 'i', 'i', 'was', 'favourite', 'as', 'on', 'she', 'they', 'hat', 'but', 'already', 'most', 'was', 'scares', 'minor', 'if', 'flash', 'was', 'well', 'also', 'good', '8', 'older', 'was', 'with', 'enjoy', 'used', 'enjoy', 'phone', 'too', \"i'm\", 'of', 'you', 'an', 'job', 'br', 'only', 'women', 'than', 'robot', 'to', 'was', 'with', 'these', 'unexpected', 'sure', 'little', 'sure', 'guy', 'sure', 'on', 'was', 'one', 'your', 'life', 'was', 'children', 'in', 'particularly', 'only', 'yes', 'she', 'sort', 'is', 'jerry', 'but', 'so', 'stories', 'them', 'final', 'known', 'to', 'have', 'does', 'such', 'most', 'that', 'supposed', 'imagination', 'very', 'moving', 'and', 'only', 'yes', 'this', 'was', 'seconds', 'for', 'imagination', 'on', 'this', 'of', 'and', 'to', 'plays', 'that', 'nights', 'to', 'for', 'supposed', 'still', 'been', 'last', 'fan', 'always', 'your', 'bit', 'that', 'strong', 'said', 'clean', 'knowing', 'br', 'theory', 'to', 'car', 'masterpiece', 'out', 'in', 'also', 'show', 'for', \"film's\", 'was', 'tale', 'have', 'flash', 'but', 'look', 'part', \"i'm\", 'film', 'as', 'to', 'and', 'is', 'script', 'hard', 'br', 'only', 'acting']\n",
            "---label---\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "#the review is stored as a sequence of integers. \n",
        "# These are word IDs that have been pre-assigned to individual words, and the label is an integer\n",
        "\n",
        "print('---review---')\n",
        "print(X_train[4])\n",
        "print('---label---')\n",
        "print(y_train[4])\n",
        "\n",
        "# to get the actual review\n",
        "word2id = imdb.get_word_index()\n",
        "id2word = {i: word for word, i in word2id.items()}\n",
        "print('---review with words---')\n",
        "print([id2word.get(i, ' ') for i in X_train[4]])\n",
        "print('---label---')\n",
        "print(y_train[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NUyS_61b3FYR"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout, SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "h6upWxEWI5VC"
      },
      "outputs": [],
      "source": [
        "#pad sequences (write your code here)\n",
        "\n",
        "max_words = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RcCOpeNI5VF",
        "outputId": "ded54713-4a36-4c32-ac6e-ee3f1f96f30c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 500, 32)           160000    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 100)               13300     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 173,401\n",
            "Trainable params: 173,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "#design a RNN model (write your code)\n",
        "\n",
        "embedding_size=32\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
        "model.add(SimpleRNN(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "InQ2TED3I5VI"
      },
      "outputs": [],
      "source": [
        "#train and evaluate your model\n",
        "#choose your loss function and optimizer and mention the reason to choose that particular loss function and optimizer\n",
        "# use accuracy as the evaluation metric\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBO6hRHDdRLM"
      },
      "source": [
        "We have used binary crossentropy because it less simple but more effective, it gave better results than the other.\n",
        "https://towardsdatascience.com/why-and-how-to-use-cross-entropy-4e983cbdd873 this article also helped me.\n",
        "\n",
        "Adam optimizer nearly always works better, faster and more reliably reaches a global minimum. Hence, the choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6A9Q0xmI5VJ",
        "outputId": "e9816079-63c6-4d57-e29a-afabb7821834"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "390/390 [==============================] - 243s 616ms/step - loss: 0.6817 - accuracy: 0.5554 - val_loss: 0.6629 - val_accuracy: 0.6406\n",
            "Epoch 2/3\n",
            "390/390 [==============================] - 238s 612ms/step - loss: 0.5659 - accuracy: 0.7077 - val_loss: 0.5778 - val_accuracy: 0.7188\n",
            "Epoch 3/3\n",
            "390/390 [==============================] - 236s 606ms/step - loss: 0.5661 - accuracy: 0.7026 - val_loss: 0.6832 - val_accuracy: 0.6250\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5db9ea0850>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 64\n",
        "num_epochs = 3\n",
        "\n",
        "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
        "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
        "\n",
        "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTXG__EmI5VM",
        "outputId": "94c7baa1-ea04-4a77-e347-e61907282452"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.633840024471283\n"
          ]
        }
      ],
      "source": [
        "#evaluate the model using model.evaluate()\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test accuracy:', scores[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1uSo8DgI5VN"
      },
      "source": [
        "# **LSTM**\n",
        "\n",
        "Instead of using a RNN, now try using a LSTM model and compare both of them. Which of those performed better and why ?\n",
        "\n",
        "LSTM was much better and faster than SimpleRNN. LSTM solves the problem of vanishing/exploding gradient. Also it retains the context for a longer time. Hence more precise in many cases.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bk4rLYHwI5VP",
        "outputId": "c0e8f078-1bf1-4ec4-ce3c-ad015ad5cd86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 500, 32)           160000    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               53200     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "390/390 [==============================] - 35s 80ms/step - loss: 0.4447 - accuracy: 0.7833 - val_loss: 0.2362 - val_accuracy: 0.9219\n",
            "Epoch 2/3\n",
            "390/390 [==============================] - 31s 79ms/step - loss: 0.2842 - accuracy: 0.8847 - val_loss: 0.2585 - val_accuracy: 0.8906\n",
            "Epoch 3/3\n",
            "390/390 [==============================] - 31s 78ms/step - loss: 0.2378 - accuracy: 0.9066 - val_loss: 0.2774 - val_accuracy: 0.8750\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5db191fb10>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_size=32\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(loss='binary_crossentropy', \n",
        "             optimizer='adam', \n",
        "             metrics=['accuracy'])\n",
        "\n",
        "batch_size = 64\n",
        "num_epochs = 3\n",
        "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
        "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
        "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBtRY9jmI5VQ"
      },
      "source": [
        "Perform Error analysis and explain using few examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrs2ylDaI5VR",
        "outputId": "1ad09795-0dea-4f9c-988b-91aa3cb0b157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.8646000027656555\n"
          ]
        }
      ],
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test accuracy:', scores[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVOoXbFgi6sJ"
      },
      "source": [
        "Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSlInjODi6Qi",
        "outputId": "309e6f8e-d00b-44f1-9396-59bec901ddc1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.98595285],\n",
              "       [0.40482894],\n",
              "       [0.13553768],\n",
              "       [0.9974136 ],\n",
              "       [0.92158026],\n",
              "       [0.9409646 ],\n",
              "       [0.02356816],\n",
              "       [0.96785873],\n",
              "       [0.96684086]], dtype=float32)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_man, y_man = X_test[1:10], y_test[1:10]\n",
        "test_transform = sequence.pad_sequences(X_man, maxlen=500)\n",
        "\n",
        "prediction = model.predict(test_transform)\n",
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDcTGE6RjLPX",
        "outputId": "dcaba509-41a9-4fdd-8f59-526e0e0de8a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "For the BoW corresponding to 0 sentence:\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        received and if time done for room and viewer as cartoon of gives to forgettable br be because many these of and and contained gives it wreck scene to more was two when had find as you another it of themselves probably who and storytelling if itself by br about 1950's films not would effects that her box to miike for if hero close seek end is very together movie of and got say kong and fred close bore there is playing lot of and pan place trilogy of lacks br of their time much this men as on it is telling program br and okay and to frustration at corner and she of sequences to political clearly in of drugs keep guy i i was throwing room and as it by br be plot many for occasionally film and boyfriend difficult kid as you it failed not if gerard to if woman in and is police fi spooky or of self what have pretty in can so suit you good 2 which why super as it main of my i i Â– if time screenplay in same this remember and have action one in realistic that better of lessons\n",
            "Ground Truth: 1\n",
            "Model Prediction: 0.9859528541564941\n",
            "\n",
            "\n",
            "For the BoW corresponding to 1 sentence:\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        reaching fact of and and and of 90s to them book are is and and and and they funniest is white courage and vegas wooden br of gender and unfortunately of 1968 no of years and and true up and and but 3 all ordinary be and to and were deserve film and and of creative br comes their kung who is and and out new all it incomprehensible it episode much that's including i i cartoon of my certain no as and over you with way to cartoon of enough for that with way who is finished and they of and br for and and stunts black that story at actual in can as movie is and has though songs and action it's action his one me and and this second no all way and not lee and be moves br figure of you boss movie is and 9 br propaganda and and after at of smoke splendid snow saturday it's results this of load it's think class br think cop for games make southern things to it and who and if is boyfriend you which is tony by this make and too not make above it even background\n",
            "Ground Truth: 1\n",
            "Model Prediction: 0.4048289358615875\n",
            "\n",
            "\n",
            "For the BoW corresponding to 2 sentence:\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              the was stick did as roles br on take as my was although except torture in perspective of goes he's was big people for was into out improved has that as with boy weapon of seems for ago film of performances production he time relationship not of grade great he jean misses was rather is boat say around thought to was well constructed except much take was story his people star of blood of over fun end this as on other of killer this as on it and film about history in of come br and was saying was three her length has about to about unusual most was story one let's town of genre when is seriously would with long only king's to future deep i'm dvd have can about people friends of here other it especially fan often somewhere br doesn't characters for he means her seemed states by well potential can when it never means movie so night bad he and daughter film of unusual are of goes her them such of number big bad one left bloody\n",
            "Ground Truth: 0\n",
            "Model Prediction: 0.13553768396377563\n",
            "\n",
            "\n",
            "For the BoW corresponding to 3 sentence:\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                the just good because great cold watching is minute each shirley completely to was several as b i i as b gave compared rest not includes we if main that movie sometimes movie have sex man endearing of feet he played to and from into pot have and man second hand in and watching his offering as b it other and to it taste bit i i in perfect as slowly truth was one in perfect only deliver sleazy has thrown not wonder classic as b satisfied at main that i i their among among without didn't later if for very and didn't clearly and didn't forget didn't\n",
            "Ground Truth: 1\n",
            "Model Prediction: 0.9974135756492615\n",
            "\n",
            "\n",
            "For the BoW corresponding to 4 sentence:\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                the watching boy and as on interesting never aunt an like did as on real and badly to and of purchased but that eyed average one in exploitation that them final realistic taxi but shock was does dvd to shock this as on off is very together to was fantastic scares some such badly victims maybe as on are year it's are unknown this factor and they there's was fantastic life think taxi as it is alexander very on to real at life who an of production this of actually believes then also in can that to was two from real that real they there's at maybe those are of journey as on thing met is 8 and that fairly of now 10 watching any years as on into at are year\n",
            "Ground Truth: 1\n",
            "Model Prediction: 0.9215802550315857\n",
            "\n",
            "\n",
            "For the BoW corresponding to 5 sentence:\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        he porno and film both derek hysterical or is gross they of try br of letting of 'the br of paul it meaningless and may of and constantly to is again and like and she plastic in and any in known is wants she br is annoyed school and this fact watch never instantly who is and massive it of actresses and br of werewolf and this and this and to lines is and disappointment br of fact br of and and i i of home br is got killer lame in is imdb and and things of letting this is paul for there will and who mirror this obsessed and who dancers and this 2004 to ready and this of and as paul it running shoes or co repeated marriage burned some when away with see is strange father share i i and it is you for of brooklyn we're and that but though example recognize to that but of and that and br leading to and film of simplistic and br of and and and make suspense step there will are you al like one brenda to see compared movements are health and this and drama and gore\n",
            "Ground Truth: 1\n",
            "Model Prediction: 0.9409645795822144\n",
            "\n",
            "\n",
            "For the BoW corresponding to 6 sentence:\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                the of and animation and male it and in and explanation and male take no and and and risk this kill in exploitation is vhs fred in of and be male it mentally who and male watch is popular catch know and it and or kill is and and for and male isn't and male her for would well thousands about and heat as it and to of universe form this did her people and to and of hollywood br of you furthermore who film reading to they of here and male lines enemy not like it of help i i of male their it of time buy treatment for it short in classic to pay is their may comedic make is getting using more he either watched yourself g an br really he judge do 7 to commercial annie make out so told rest you and there movies plot jack this having sidekick to childhood any this so family stopped stunning make his makes your not make present in at and to explanation one bit get still been as\n",
            "Ground Truth: 0\n",
            "Model Prediction: 0.023568157106637955\n",
            "\n",
            "\n",
            "For the BoW corresponding to 7 sentence:\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            the until me is both did detail film and and ego interpretation not again br while and one corrupt of underrated br my of its meet than of metal creatures protect and many really one both he's lost adaptation as by it waiting film freddy 7 and and to dude if is video and br and to around nearly and hilarious that with claim but make cube excellent instead really he family and this as hard to took and element br graphics impression of see stewart biggest comments really and it make version throw to and serious in why br of plot many way this as soon again br any saw she in joey and i've chair br and family think because and ego you it apparent in as by old if is noise\n",
            "Ground Truth: 0\n",
            "Model Prediction: 0.9678587317466736\n",
            "\n",
            "\n",
            "For the BoW corresponding to 8 sentence:\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        that comedies is and seemed you wasn't in of too of soul with point present in at to fight fits i i close decade teacher movie of soul to be and competition hasn't faced film and refreshing and besides rex easy this and br of and exciting naked shows be humanity this peter and and of and allow and this themselves liners lugosi br and and animation projects to and and of and via and directing faced and give movie high to movie of soul of attention and i'd this shot boring course rex to and go american decade to and pushing of 1950's able br suppose and i i more he good holds and this as you has of see and was well had come some it is soundtrack in of guy this good details really was two it basically episodes in of too as you it is attention and matter more else interesting that's my in christ pushing sorry part are i i asian as it is imagination very you was fight wonderful doesn't as this and film of how to them and but don't very of original after one will me that worker 4 aforementioned to decade\n",
            "Ground Truth: 1\n",
            "Model Prediction: 0.9668408632278442\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(y_man)):\n",
        "  print()\n",
        "  print(\"For the BoW corresponding to\",i, \"sentence:\")\n",
        "  print(f\"{' '.join([id2word.get(j, ' ') for j in X_man[i]])}\")\n",
        "  print(\"Ground Truth:\", y_man[i])\n",
        "  print(\"Model Prediction:\", prediction[i][0])\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8lKmsxeBjjWh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jktvyAvjVrB",
        "outputId": "01a1736d-48d8-4b8f-9ffb-fbdb1a072d2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.50509757]], dtype=float32)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_text = ('The movie was not good')\n",
        "sample_text = sample_text.lower().split(' ')\n",
        "word2id = imdb.get_word_index()\n",
        "\n",
        "id2word = {i: word for word, i in word2id.items()}\n",
        "sample_text_transform = [word2id[x] for x in sample_text]\n",
        "test_text_transform = sequence.pad_sequences(np.array(sample_text_transform).reshape(1,-1), maxlen=500)\n",
        "\n",
        "prediction = model.predict(test_text_transform)\n",
        "prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A973MHJdkOVe"
      },
      "source": [
        "Model worked good on the 9 test sentences above, but it predicts the sentiment of the `sample_text` sentence wrong."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "RNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
